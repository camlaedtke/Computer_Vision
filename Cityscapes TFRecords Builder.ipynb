{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a TFRecords Dataset for Image Segmentation\n",
    "\n",
    "\n",
    "Assumes the channel-wise mean and standard deviation have been computed over the dataset and stored in a `.json` file. \n",
    "\n",
    "\n",
    "### Create a dictionary for each image/segmentation pair\n",
    "\n",
    "We want a list of dictionaries, one for each image/segmentation pair. Should include all relevant information including file locations, image dimensions, and labels.\n",
    "\n",
    "Steps\n",
    "- Extract list of image file names, shuffle list\n",
    "- For each file in the list of files ...\n",
    "    - Load the image into an array\n",
    "    - Load the segmentation mask (same file name but .png instead of .jpg), convert to array and cast as `np.uint8`\n",
    "    - Get dimensions of image and mask\n",
    "    - Parse the file name to get the breed, and breed ID\n",
    "    - Store location of image and mask, as well as the image dimensions and labels, inside of a dictionary\n",
    "    - Append the dictionary to a list\n",
    "    \n",
    "    \n",
    "### Use dictionary to serialize dataset and store as TFRecord\n",
    "\n",
    "Iterate over list of dictionaries \n",
    "- Load image and mask arrays\n",
    "- Perform preprocessing (this example normalizes color channels)\n",
    "- Serialize image and mask into byte-strings\n",
    "- Write into a file using a `tf.io.TFRecordsWriter`\n",
    "\n",
    "\n",
    "### Verify by reading from TFRecord\n",
    "\n",
    "Important note: Need to manualy specify the image depth and mask depth in `read_tfrecord()`, as well as data type. Otherwise model with throw an error during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import cv2\n",
    "import PIL\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from cityscapes_loading import normalize_channels\n",
    "from label_utils import get_labels\n",
    "\n",
    "\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 512\n",
    "n_classes = 34\n",
    "\n",
    "labels = get_labels()\n",
    "# id to label object\n",
    "id2label = { label.id : label for label in labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def load_image_rgb_data(fp):\n",
    "    # Opening JSON file \n",
    "    with open(fp, 'r') as openfile: \n",
    "        # Reading from json file \n",
    "        image_info = json.load(openfile) \n",
    "    info_dict = {\n",
    "        \"R_MEAN\": float(image_info[\"R_MEAN\"]),\n",
    "        \"G_MEAN\": float(image_info[\"G_MEAN\"]),\n",
    "        \"B_MEAN\": float(image_info[\"B_MEAN\"]),\n",
    "        \"R_STD\": float(image_info[\"R_STD\"]),\n",
    "        \"G_STD\": float(image_info[\"B_STD\"]),\n",
    "        \"B_STD\": float(image_info[\"G_STD\"]),\n",
    "    }\n",
    "    return info_dict\n",
    "\n",
    "\n",
    "def normalize_image_channels(x_img, rgb_data):\n",
    "    x_img[:,:,0] -= rgb_data['R_MEAN']\n",
    "    x_img[:,: 1] -= rgb_data['G_MEAN']\n",
    "    x_img[:,: 2] -= rgb_data['B_MEAN']\n",
    "\n",
    "    x_img[:,:,0] /= rgb_data['R_STD']\n",
    "    x_img[:,: 1] /= rgb_data['G_STD']\n",
    "    x_img[:,: 2] /= rgb_data['B_STD']\n",
    "    \n",
    "    return x_img\n",
    "    \n",
    "    \n",
    "def extract_cityscape_data_info(path, subset=None):\n",
    "    \n",
    "    ids_temp = next(os.walk(path + \"annotations\"))[2]\n",
    "    ids_1 = []\n",
    "    for i in ids_temp:\n",
    "        if i.endswith(\"labelIds.png\"):\n",
    "            id_temp = i.split(\"\\\\\")\n",
    "            id_temp = id_temp[-1][:-20]\n",
    "            ids_1.append(id_temp)\n",
    "            \n",
    "    random.seed(2019)\n",
    "    id_order = np.arange(len(ids_1))\n",
    "    np.random.shuffle(id_order)\n",
    "    \n",
    "    ids = []\n",
    "    for i in range(len(id_order)):\n",
    "        ids.append(ids_1[np.int(id_order[i])])\n",
    "        \n",
    "    print(\"Number of images: \" + str(len(ids)))\n",
    "    \n",
    "    image_data = []\n",
    "            \n",
    "    for n, id_ in enumerate(ids):\n",
    "        print(\"\\r Processing %s \\ %s \" % (n+1, len(ids)), end='')\n",
    "        \n",
    "        id_image = id_ + \"_leftImg8bit.png\"\n",
    "        image_filename = path + \"images\\\\\" + id_image\n",
    "        id_mask = id_ + \"_gtFine_labelIds.png\"\n",
    "        mask_filename = path + \"annotations\\\\\" + id_mask\n",
    "        \n",
    "        # load image\n",
    "        img = load_img(image_filename)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = x_img.squeeze()\n",
    "        \n",
    "        # load mask\n",
    "        mask = img_to_array(load_img(mask_filename, color_mode = \"grayscale\"))\n",
    "        mask = mask.astype(np.uint8)\n",
    "        \n",
    "        # get size info\n",
    "        img_height = x_img.shape[0]\n",
    "        img_width = x_img.shape[1]\n",
    "        img_depth = x_img.shape[2]\n",
    "        mask_depth = mask.shape[2]\n",
    "        \n",
    "        # add to list of dicts\n",
    "        image_dict = {\n",
    "            \"image_filename\": image_filename,\n",
    "            \"mask_filename\": mask_filename,\n",
    "            \"height\": img_height,\n",
    "            \"width\": img_width,\n",
    "            \"image_depth\": img_depth,\n",
    "            \"mask_depth\": mask_depth,\n",
    "        }\n",
    "\n",
    "        image_data.append(image_dict)\n",
    "        \n",
    "        if (subset is not None) and (n == subset-1):\n",
    "            break\n",
    "    \n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    # If the value is an eager tensor BytesList won't unpack a string from an EagerTensor.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def serialize_example(image, mask, image_shape, mask_shape):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(image),\n",
    "        'segmentation':  _bytes_feature(mask),\n",
    "        'height': _int64_feature(image_shape[0]),\n",
    "        'width': _int64_feature(image_shape[1]),\n",
    "        'image_depth': _int64_feature(image_shape[2]),\n",
    "        'mask_depth': _int64_feature(mask_shape[2]),\n",
    "    }\n",
    "    #  Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "def write_tfrecord(tfrecord_dir, image_data, normalize=False, rgb_data=None):\n",
    "    \n",
    "    with tf.io.TFRecordWriter(tfrecord_dir) as writer:\n",
    "        for n, datapoint in enumerate(image_data):\n",
    "            print(\"\\r Writing %s \\ %s \" % (n+1, len(image_data)), end='')\n",
    "\n",
    "            # get image\n",
    "            img = load_img(datapoint[\"image_filename\"])\n",
    "            img_array = img_to_array(img)\n",
    "            if normalize:\n",
    "                img_array = normalize_image_channels(img_array, rgb_data)\n",
    "            else:\n",
    "                img_array = img_array.astype(np.uint8)\n",
    "            \n",
    "            img_bytes = tf.io.serialize_tensor(img_array)\n",
    "            image_shape = img_array.shape\n",
    "\n",
    "            # get mask\n",
    "            mask = load_img(datapoint[\"mask_filename\"], color_mode=\"grayscale\")\n",
    "            mask_array = img_to_array(mask)\n",
    "            mask_array = mask_array.astype(np.uint8)\n",
    "            mask_bytes = tf.io.serialize_tensor(mask_array)\n",
    "            mask_shape = mask_array.shape\n",
    "\n",
    "            example = serialize_example(img_bytes, mask_bytes, image_shape, mask_shape)\n",
    "            writer.write(example)\n",
    "\n",
    "\n",
    "        \n",
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature((), tf.string),\n",
    "        'segmentation': tf.io.FixedLenFeature((), tf.string),\n",
    "        'height': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'width': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'image_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'mask_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    \n",
    "    image = tf.io.parse_tensor(example['image'], out_type = tf.uint8)\n",
    "    image_shape = [example['height'], example['width'], 3]\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    \n",
    "    mask = tf.io.parse_tensor(example['segmentation'], out_type = tf.uint8)\n",
    "    mask_shape = [example['height'], example['width'], 1]\n",
    "    mask = tf.reshape(mask, mask_shape)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_dataset_from_tfrecord(tfrecord_dir):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_dir)\n",
    "    parsed_dataset = tfrecord_dataset.map(read_tfrecord)\n",
    "    return parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Cityscapes\\\\\"\n",
    "image_rgb_data = load_image_rgb_data(fp=\"Cityscapes\\\\data_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info = extract_cityscape_data_info(path=path, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = 2780\n",
    "TEST_LENGTH = 695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = image_info[0:TRAIN_LENGTH]\n",
    "test_info = image_info[TRAIN_LENGTH:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord_dir = 'Cityscapes\\\\train.tfrecords'\n",
    "test_tfrecord_dir = 'Cityscapes\\\\test.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecord(tfrecord_dir=train_tfrecord_dir, image_data=train_info, normalize=False, rgb_data=image_rgb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecord(tfrecord_dir=test_tfrecord_dir, image_data=test_info, normalize=False, rgb_data=image_rgb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "test_dataset = get_dataset_from_tfrecord(test_tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (image, mask) in enumerate(train_dataset.take(4)):\n",
    "    sample_image = image.numpy()\n",
    "    sample_mask = mask.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
