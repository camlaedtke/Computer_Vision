{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from label_utils import get_labels, get_train_labels\n",
    "from custom_models import unet, segnet, unet_xception\n",
    "from deeplabV3_xception import deeplabv3\n",
    "from plot_utils import plot_history, plot_dice_and_iou\n",
    "\n",
    "K.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "def enable_amp():\n",
    "    policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "    mixed_precision.set_policy(policy)\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices)\n",
    "# enable_amp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature((), tf.string),\n",
    "        'segmentation': tf.io.FixedLenFeature((), tf.string),\n",
    "        'height': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'width': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'image_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'mask_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    \n",
    "    image = tf.io.parse_tensor(example['image'], out_type = tf.uint8)\n",
    "    image_shape = [example['height'], example['width'], 3]\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    \n",
    "    mask = tf.io.parse_tensor(example['segmentation'], out_type = tf.uint8)\n",
    "    mask_shape = [example['height'], example['width'], 1]\n",
    "    mask = tf.reshape(mask, mask_shape)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_dataset_from_tfrecord(tfrecord_dir):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_dir)\n",
    "    parsed_dataset = tfrecord_dataset.map(read_tfrecord)\n",
    "    return parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord_dir = 'Cityscapes\\\\fine_train.tfrecords'\n",
    "test_tfrecord_dir = 'Cityscapes\\\\fine_test.tfrecords'\n",
    "\n",
    "img_height = 256\n",
    "img_width = 512\n",
    "n_classes = 19\n",
    "\n",
    "labels = get_labels()\n",
    "id2label = { label.id : label for label in labels }\n",
    "trainId2label = { label.trainId : label for label in labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mask_to_categorical(image, mask):\n",
    "    mask = tf.squeeze(mask)\n",
    "    mask = tf.one_hot(tf.cast(mask, tf.int32), n_classes)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image_test(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords_dataset = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "test_tfrecords_dataset = get_dataset_from_tfrecord(test_tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: resize the images and masks, flip them, \n",
    "train = train_tfrecords_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = test_tfrecords_dataset.map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_trainid(mask):\n",
    "    mask_train = np.zeros((mask.shape[0], mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
    "    for i in range(0,34):\n",
    "        mask_train[mask[:,:,0]==i] = id2label[i].trainId\n",
    "    return mask_train\n",
    "\n",
    "\n",
    "def label_to_rgb(mask):\n",
    "    mask_rgb = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    for i in range(0,n_classes):\n",
    "        mask_rgb[mask[:,:,0]==i] = trainId2label[i].color\n",
    "    #mask_rgb[mask[:,:,0]==255] = trainId2label[255].color\n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "def display(display_list, title=False):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    if title:\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        if title:\n",
    "            plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test.take(3):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    \n",
    "sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = unet(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "# model = segnet(input_height=img_height, input_width=img_width, n_classes=34)\n",
    "# model = unet_xception(input_height=img_height, input_width=img_width, n_classes=34)\n",
    "model = deeplabv3(input_height=img_height, input_width=img_width, n_classes=n_classes, load_weights=False)\n",
    "plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"saved_models\\\\deeplab_xception_cityscapes.h5\"\n",
    "model.load_weights(model_name, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrays_from_dataset(dataset, n_samples):\n",
    "    X_samples = np.zeros((n_samples, img_height, img_width, 3))\n",
    "    y_samples = np.zeros((n_samples, img_height, img_width, n_classes))\n",
    "\n",
    "    for idx, (image, mask) in enumerate(dataset):\n",
    "        X_samples[idx] = image.numpy()\n",
    "        y_samples[idx] = mask.numpy()\n",
    "        if idx == (n_samples-1):\n",
    "            break\n",
    "            \n",
    "    return X_samples, y_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "X_test, y_test = arrays_from_dataset(dataset=test, n_samples=n_samples)\n",
    "print(\"X_test.shape: {} , y_test.shape: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 3\n",
    "sample_image = X_test[img_num]\n",
    "sample_mask= np.expand_dims(np.argmax(y_test[img_num], axis=-1), axis=-1)\n",
    "sample_mask = label_to_rgb(sample_mask)\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.squeeze(pred_mask, axis=0)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask = label_to_rgb(pred_mask.numpy())\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def show_predictions():\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "    \n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dice(y_true, y_pred):\n",
    "    dice = 0.0\n",
    "    smooth = 1.0\n",
    "    class_dice = []\n",
    "    for i in range(0, n_classes):\n",
    "        intersection = K.sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = K.sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2))\n",
    "        dice_temp = K.mean((2. * intersection + smooth) / (union + smooth))\n",
    "        class_dice.append(dice_temp.numpy())\n",
    "        dice = dice + dice_temp\n",
    "    mean_dice = dice / (n_classes)\n",
    "    return class_dice, round(mean_dice.numpy(), 4)\n",
    "\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    iou = 0.0\n",
    "    smooth = 1.0\n",
    "    class_iou = []\n",
    "    for i in range(0, n_classes):\n",
    "        intersection = K.sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = K.sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2)) - intersection\n",
    "        iou_temp = K.mean((intersection + smooth) / (union + smooth))\n",
    "        class_iou.append(iou_temp.numpy())\n",
    "        iou = iou + iou_temp\n",
    "    mean_iou = iou / (n_classes)\n",
    "    return class_iou, round(mean_iou.numpy(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[0:n_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dice, mean_dice = mean_dice(y_test[0:n_samples], y_pred)\n",
    "print(\"MEAN DICE\")\n",
    "print(\"Best: {} \\nWorst: {}\\nAverage: {}\".format(max(class_dice), min(class_dice), mean_dice))\n",
    "class_iou, mean_iou = mean_iou(y_test[0:n_samples], y_pred)\n",
    "print(\"MEAN IOU\")\n",
    "print(\"Best: {} \\nWorst: {}\\nAverage: {}\".format(max(class_iou), min(class_iou), mean_iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dice_and_iou(trainId2label=trainId2label, n_classes=n_classes, class_dice=class_dice, class_iou=class_iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
