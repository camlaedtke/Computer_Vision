{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import PIL\n",
    "import glob\n",
    "import random\n",
    "import imageio\n",
    "import sklearn\n",
    "import itertools\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from label_utils import get_labels\n",
    "\n",
    "K.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "\n",
    "def enable_amp():\n",
    "    policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "    mixed_precision.set_policy(policy)\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices)\n",
    "enable_amp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 512\n",
    "n_classes = 34\n",
    "\n",
    "labels = get_labels()\n",
    "# id to label object\n",
    "id2label = { label.id : label for label in labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, shuffle=False, subset=None):\n",
    "    \n",
    "    ids_temp = next(os.walk(path + \"annotations\"))[2]\n",
    "    ids_1 = []\n",
    "    for i in ids_temp:\n",
    "        if i.endswith(\"labelIds.png\"):\n",
    "            id_temp = i.split(\"\\\\\")\n",
    "            id_temp = id_temp[-1][:-20]\n",
    "            ids_1.append(id_temp)\n",
    "            \n",
    "    ids = []\n",
    "    if shuffle:\n",
    "        random.seed(2019)\n",
    "        id_order = np.arange(len(ids_1))\n",
    "        np.random.shuffle(id_order)\n",
    "        for i in range(len(id_order)):\n",
    "            ids.append(ids_1[np.int(id_order[i])])\n",
    "    else:\n",
    "        ids = ids_1\n",
    "        \n",
    "    if (subset is not None):\n",
    "        X = np.zeros((subset, img_height, img_width, 3), dtype=np.float32)\n",
    "        y = np.zeros((subset, img_height, img_width, 1), dtype=np.uint8)\n",
    "        print(\"Number of images: \" + str(subset))\n",
    "    else:\n",
    "        X = np.zeros((len(ids), img_height, img_width, 3), dtype=np.float32)\n",
    "        y = np.zeros((len(ids), img_height, img_width, 1), dtype=np.uint8)\n",
    "        print(\"Number of images: \" + str(len(ids)))\n",
    "        \n",
    "    for n, id_ in enumerate(ids):\n",
    "        \n",
    "        print(\"\\r Loading %s \\ %s \" % (n+1, len(ids)), end='')\n",
    "        \n",
    "        # load images\n",
    "        id_image = id_ + \"_leftImg8bit.png\"\n",
    "        img = load_img(path + \"images\\\\\" + id_image)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (img_height, img_width, 3), mode='constant', preserve_range = True)\n",
    "        \n",
    "        # load masks\n",
    "        id_mask = id_ + \"_gtFine_labelIds.png\"\n",
    "        mask = load_img(path + \"annotations\\\\\" + id_mask, color_mode = \"grayscale\")\n",
    "        mask = img_to_array(mask)\n",
    "        mask = cv2.resize(mask, (img_width, img_height), interpolation = cv2.INTER_NEAREST)\n",
    "        mask = np.expand_dims(mask, 2)\n",
    "        #mask = to_categorical(mask, n_classes)\n",
    "        \n",
    "        # save images\n",
    "        X[n, ...] = x_img.squeeze()\n",
    "        y[n] = mask.astype(np.uint8)\n",
    "        \n",
    "        if (subset is not None) and (n == subset-1):\n",
    "            break\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = get_data(path=\"Cityscapes\\\\\", shuffle=True, subset=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_rgb(mask):\n",
    "    \n",
    "    mask_rgb = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(0,n_classes):\n",
    "        mask_rgb[mask[:,:,0]==i] = id2label[i].color\n",
    "    \n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "def display(display_list, title=False):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    if title:\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        if title:\n",
    "            plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 5\n",
    "\n",
    "sample_image = X_all[img_num]\n",
    "sample_mask = y_all[img_num]\n",
    "sample_mask = label_to_rgb(sample_mask)\n",
    "\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "TRAIN_LENGTH = len(X_train)\n",
    "TEST_LENGTH = len(X_test)\n",
    "BUFFER_SIZE = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32) / 255\n",
    "X_test = X_test.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mask_to_categorical(image, mask):\n",
    "    mask = tf.squeeze(mask)\n",
    "    mask = tf.one_hot(tf.cast(mask, tf.int32), n_classes)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_ds = train_ds.map(mask_to_categorical, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "valid_ds = valid_ds.map(mask_to_categorical)\n",
    "\n",
    "train_dataset = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in valid_ds.take(2):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    \n",
    "sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_height=img_height,  input_width=img_width, n_classes = 3):\n",
    "    \n",
    "    img_input = tf.keras.layers.Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    # -------------------------- Encoder --------------------------\n",
    "    \n",
    "    c1 = Conv2D(64, 3, padding='same', activation=\"selu\")(img_input)\n",
    "    c1 = Conv2D(64, 3, padding='same', activation=\"selu\")(c1)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, 3, padding='same', activation=\"selu\")(p1)\n",
    "    c2 = Conv2D(128, 3, padding='same', activation=\"selu\")(c2)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "    p2 = Dropout(0.1)(p2)\n",
    "    \n",
    "    c3 = Conv2D(256, 3, padding='same', activation=\"selu\")(p2)\n",
    "    c3 = Conv2D(256, 3, padding='same', activation=\"selu\")(c3)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    p3 = Dropout(0.2)(p3)\n",
    "    \n",
    "    c4 = Conv2D(512, 3, padding='same', activation=\"selu\")(p3)\n",
    "    c4 = Conv2D(512, 3, padding='same', activation=\"selu\")(c4)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "    p4 = Dropout(0.2)(p4)\n",
    "    \n",
    "    # ------------------------ Bottleneck -------------------------\n",
    "    \n",
    "    c5 = Conv2D(1024, 3, padding='same', activation=\"selu\")(p4)\n",
    "    c5 = Conv2D(1024, 3, padding='same', activation=\"selu\")(c5)\n",
    "    c5 = Dropout(0.5)(c5)\n",
    "    \n",
    "    # -------------------------- Decoder --------------------------\n",
    "    \n",
    "    u6 = concatenate([UpSampling2D(2)(c5), c4])\n",
    "    c6 = Conv2D(512, 3, padding='same')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation('selu')(c6)\n",
    "    c6 = Conv2D(256, 3, padding='same')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation('selu')(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    \n",
    "    u7 = concatenate([UpSampling2D(2)(c6), c3])\n",
    "    c7 = Conv2D(256, 3, padding='same')(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation('selu')(c7)\n",
    "    c7 = Conv2D(128, 3, padding='same')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation('selu')(c7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "\n",
    "    u8 = concatenate([UpSampling2D(2)(c7), c2])\n",
    "    c8 = Conv2D(128, 3, padding='same')(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation('selu')(c8)\n",
    "    c8 = Conv2D(64, 3, padding='same')(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation('selu')(c8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "\n",
    "    u9 = concatenate([UpSampling2D(2)(c8), c1]) \n",
    "    c9 = Conv2D(64, 3, padding='same')(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Activation('selu')(c9)\n",
    "    c9 = Conv2D(64, 3, padding='same')(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Activation('selu')(c9)\n",
    "    c9 = Conv2D(n_classes, 3, padding='same')(c9)\n",
    "    \n",
    "    output = Activation(\"softmax\", dtype='float32')(c9)\n",
    "    \n",
    "    return tf.keras.Model(inputs=img_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    dice = 0.0\n",
    "    smooth = 1.0\n",
    "    for i in range(1, n_classes):\n",
    "        intersection = y_true[:,:,i] * y_pred[:,:,i]\n",
    "        all_ = y_true[:,:,i] + y_pred[:,:,i]\n",
    "        intersection = K.sum(intersection, 1)\n",
    "        all_ = K.sum(all_, 1)\n",
    "        temp = (2. * intersection + smooth) / (all_ + smooth)\n",
    "        temp = K.mean(temp)\n",
    "        dice = dice + temp\n",
    "    return dice / (n_classes-1)\n",
    "\n",
    "\n",
    "def cce_dice_loss(y_true, y_pred):\n",
    "    return (tf.keras.losses.categorical_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)) + 1\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return (1 - dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(input_height=img_height, input_width=img_width, n_classes=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.squeeze(pred_mask)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask = label_to_rgb(pred_mask.numpy())\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def show_predictions():\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "\n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "        \n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"saved_models\\\\unet_pets.h5\"\n",
    "\n",
    "model.compile(optimizer = Adam(lr=1e-4),\n",
    "              loss = cce_dice_loss, \n",
    "              metrics = ['accuracy', dice_coef])\n",
    "\n",
    "callbacks = [\n",
    "    DisplayCallback(),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', patience=9, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.1, min_lr=1e-10, verbose=1),\n",
    "    ModelCheckpoint(model_name, monitor='val_loss', verbose=1, mode='min', save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "# model.load_weights(\"big_unet_model.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "VALIDATION_STEPS = TEST_LENGTH//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(train_dataset,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    validation_steps=VALIDATION_STEPS,\n",
    "                    epochs = EPOCHS,\n",
    "                    validation_data = valid_dataset,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
